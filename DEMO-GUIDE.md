# üöÄ Kubernetes Autoscaling Demo - Informaci√≥n de Acceso

## ‚úÖ Estado del Despliegue

Todo est√° correctamente desplegado y funcionando:

### üìä Componentes Activos

| Componente | Estado | Pods |
|------------|--------|------|
| Aplicaci√≥n (do-sample-app) | ‚úÖ Running | 3/3 |
| PostgreSQL | ‚úÖ Running | 1/1 |
| Prometheus Stack | ‚úÖ Running | 8/8 |
| Locust Master | ‚úÖ Running | 1/1 |
| Locust Workers | ‚úÖ Running | 2/2 |
| Metrics Server | ‚úÖ Running | 1/1 |
| HPA | ‚úÖ Active | Min:2 Max:10 |

---

## üåê URLs de Acceso

### 1. Aplicaci√≥n Principal
- **URL P√∫blica**: http://45.55.116.144
- **Estado**: ‚úÖ Funcionando correctamente

### 2. Locust (Pruebas de Carga)
- **URL Web UI**: http://138.197.240.205:8089
- **Usuario**: No requiere autenticaci√≥n
- **Target Host**: http://do-sample-app-service:8080
- **Estado**: ‚úÖ Listo para generar carga

### 3. Grafana (Monitoreo)
- **URL Local**: http://localhost:3000 (requiere port-forward)
- **Usuario**: `admin`
- **Contrase√±a**: `prom-operator`
- **Comando para acceder**:
  ```bash
  kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
  ```

### 4. Prometheus (M√©tricas)
- **URL Local**: http://localhost:9090 (requiere port-forward)
- **Comando para acceder**:
  ```bash
  kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
  ```

---

## üéØ C√≥mo Ejecutar las Pruebas de Autoscaling

### Opci√≥n 1: Usando Ansible (Recomendado)

```bash
cd ansible

# 1. Ver el estado actual
kubectl get hpa
kubectl get pods -l app=do-sample-app

# 2. Ejecutar prueba de carga con monitoreo autom√°tico
ansible-playbook run-load-test.yml
```

### Opci√≥n 2: Manual con Locust UI

1. **Abrir Locust**: http://138.197.240.205:8089

2. **Configurar la prueba**:
   - Host: `h`
   - Number of users: `100`
   - Spawn rate: `10` usuarios/segundo
   - Run time: `600` segundos (10 minutos)

3. **Iniciar la prueba**: Click en "Start swarming"

4. **Monitorear en tiempo real**:
   ```bash
   # Terminal 1: Monitorear HPA
   kubectl get hpa do-sample-app-hpa -w
   
   # Terminal 2: Monitorear Pods
   kubectl get pods -l app=do-sample-app -w
   
   # Terminal 3: Ver m√©tricas
   kubectl top pods -l app=do-sample-app
   ```

5. **Abrir Grafana** para visualizaci√≥n gr√°fica:
   ```bash
   kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
   # Ir a http://localhost:3000
   # Login: admin / prom-operator
   ```

---

## üìà Qu√© Obttp://do-sample-app-service:8080servar Durante las Pruebas

### En Locust (http://138.197.240.205:8089)
- ‚úÖ RPS (Requests per Second) incrementando
- ‚úÖ Response times manteni√©ndose bajos
- ‚úÖ Tasa de fallos cercana a 0%

### En kubectl (Terminal)
```bash
# Ver√°s algo como esto:
NAME                REFERENCE                  TARGETS                  MINPODS   MAXPODS   REPLICAS
do-sample-app-hpa   Deployment/do-sample-app   cpu: 5%/50%             2         10        2

# Despu√©s de 1-2 minutos de carga:
do-sample-app-hpa   Deployment/do-sample-app   cpu: 65%/50%            2         10        4

# En el pico:
do-sample-app-hpa   Deployment/do-sample-app   cpu: 55%/50%            2         10        7

# Pods escalando:
kubectl get pods -l app=do-sample-app
# Ver√°s nuevos pods cre√°ndose: ContainerCreating -> Running
```

### En Grafana (http://localhost:3000)

**Dashboards recomendados**:
1. **Kubernetes / Compute Resources / Namespace (Pods)**
   - Filtrar por namespace: `default`
   - Ver CPU y memoria de todos los pods

2. **Kubernetes / Compute Resources / Pod**
   - Seleccionar pods: `do-sample-app-*`
   - Ver m√©tricas individuales

3. **Crear Dashboard personalizado**:
   - Panel 1: N√∫mero de r√©plicas del deployment
   - Panel 2: CPU usage por pod
   - Panel 3: Memory usage por pod
   - Panel 4: Request rate

---

## üß™ Escenarios de Prueba Sugeridos

### Prueba 1: Scaling Progresivo (Recomendada para primera vez)
```
Usuarios: 50
Spawn Rate: 5/seg
Duraci√≥n: 5 minutos
Resultado esperado: 3-5 pods
```

### Prueba 2: Scaling Agresivo
```
Usuarios: 100
Spawn Rate: 10/seg
Duraci√≥n: 10 minutos
Resultado esperado: 6-8 pods
```

### Prueba 3: M√°ximo Stress
```
Usuarios: 200
Spawn Rate: 20/seg
Duraci√≥n: 10 minutos
Resultado esperado: 9-10 pods (l√≠mite m√°ximo)
```

### Prueba 4: Scale Down
```
1. Ejecutar prueba intensa (100-200 usuarios)
2. Detener la prueba en Locust
3. Observar c√≥mo los pods se reducen gradualmente
4. Tiempo esperado: 5-10 minutos para volver a 2 pods
```

---

## üìä Configuraci√≥n del HPA

El HPA est√° configurado para:

```yaml
M√≠nimo de r√©plicas: 2
M√°ximo de r√©plicas: 10

M√©tricas de trigger:
- CPU: 50% de utilizaci√≥n promedio
- Memory: 70% de utilizaci√≥n promedio

Comportamiento de scaling:
Scale Up:
  - Duplica pods cada 15 segundos si es necesario
  - M√°ximo 4 pods por vez
  
Scale Down:
  - Espera 5 minutos de estabilidad
  - Reduce 50% de pods cada vez
  - Comportamiento conservador
```

---

## üîç Comandos √ötiles

```bash
# Ver estado general
kubectl get all -n default
kubectl get all -n monitoring

# HPA
kubectl get hpa
kubectl describe hpa do-sample-app-hpa

# Pods y recursos
kubectl get pods -l app=do-sample-app
kubectl top pods -l app=do-sample-app
kubectl top nodes

# Logs
kubectl logs -f deployment/do-sample-app
kubectl logs -f -l app=locust-master

# Eventos de scaling
kubectl get events --sort-by='.lastTimestamp' | grep -i scale

# M√©tricas del Metrics Server
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes
kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods
```

---

## üé¨ Workflow Completo de Demostraci√≥n

1. **Preparaci√≥n** (2 minutos):
   ```bash
   # Abrir 3 terminales
   # Terminal 1:
   kubectl get hpa -w
   
   # Terminal 2:
   kubectl get pods -l app=do-sample-app -w
   
   # Terminal 3:
   kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
   ```

2. **Abrir Dashboards** (1 minuto):
   - Locust: http://138.197.240.205:8089
   - Grafana: http://localhost:3000
   - Aplicaci√≥n: http://45.55.116.144

3. **Estado Inicial** (1 minuto):
   - Mostrar HPA con CPU/Memory bajo
   - Mostrar 2-3 pods activos
   - Mostrar gr√°ficas en Grafana en estado normal

4. **Iniciar Carga** (30 segundos):
   - En Locust: 100 users, 10 spawn rate
   - Click "Start swarming"

5. **Observar Scaling Up** (3-5 minutos):
   - Ver CPU subiendo en HPA
   - Ver nuevos pods cre√°ndose
   - Ver m√©tricas en Grafana incrementando
   - Ver RPS en Locust aumentando

6. **Pico de Carga** (2-3 minutos):
   - Observar estabilizaci√≥n en 6-8 pods
   - CPU mantenido alrededor del 50%
   - Response times estables

7. **Detener Carga** (30 segundos):
   - Click "Stop" en Locust

8. **Observar Scale Down** (5-10 minutos):
   - Ver CPU bajando gradualmente
   - Ver pods termin√°ndose uno por uno
   - Vuelta a 2 pods m√≠nimos

---

## üßπ Limpieza

Cuando termines las pruebas:

```bash
# Opci√≥n 1: Con Ansible
cd ansible
ansible-playbook cleanup.yml

# Opci√≥n 2: Manual
kubectl delete -f ../manifests/locust.yaml
kubectl delete -f ../manifests/hpa.yaml
helm uninstall prometheus -n monitoring
kubectl delete namespace monitoring
```

**Nota**: La aplicaci√≥n principal permanece activa.

---

## üí° Tips para una Buena Demostraci√≥n

1. **Primero sin carga**: Muestra el estado normal (2-3 pods, CPU bajo)

2. **Explica el HPA**: Muestra la configuraci√≥n antes de empezar

3. **Carga gradual**: Empieza con 50 usuarios, luego sube a 100-200

4. **M√∫ltiples pantallas**: Locust + Grafana + Terminal es impactante

5. **Explica las m√©tricas**: CPU%, n√∫mero de r√©plicas, response time

6. **Muestra el scale down**: Demuestra que tambi√©n escala hacia abajo

7. **Compara con/sin autoscaling**: Explica qu√© pasar√≠a sin HPA

---

## üìû Troubleshooting

### HPA muestra `<unknown>`
```bash
# Esperar 1-2 minutos para m√©tricas
kubectl get deployment metrics-server -n kube-system
kubectl logs -n kube-system deployment/metrics-server
```

### Pods no escalan
```bash
kubectl describe hpa do-sample-app-hpa
# Verificar que resources est√©n configurados
kubectl describe deployment do-sample-app | grep -A 5 "Limits:"
```

### Locust no conecta
```bash
kubectl logs -l app=locust-master
# Verificar que el servicio de la app est√© correcto
kubectl get svc do-sample-app-service
```

---

## üéâ ¬°Todo Listo!

Tu entorno de autoscaling est√° completamente configurado y listo para demostraciones.

**Pr√≥ximos pasos recomendados**:
- ‚úÖ Familiar√≠zate con los dashboards de Grafana
- ‚úÖ Prueba diferentes escenarios de carga
- ‚úÖ Documenta los resultados y tiempos de scaling
- ‚úÖ Considera implementar VPA (Vertical Pod Autoscaler)
- ‚úÖ Configura alertas en Prometheus

**Documentaci√≥n completa**: Ver `ansible/README.md`
