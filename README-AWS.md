# ğŸš€ Kubernetes Autoscaling en AWS EKS

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa **autoescalado completo** (Pods y Nodos) en **AWS EKS** usando Kubernetes, con infraestructura como cÃ³digo mediante Ansible.

### âœ¨ CaracterÃ­sticas Principales

- âœ… **HPA (Horizontal Pod Autoscaler)**: Escala pods de 2 a 10 rÃ©plicas
- âœ… **Cluster Autoscaler**: Escala nodos EC2 de 2 a 5 instancias
- âœ… **PolÃ­ticas Avanzadas**: ConfiguraciÃ³n detallada de comportamiento de scaling
- âœ… **Monitoreo**: Prometheus + Grafana con dashboards preconfigurados
- âœ… **Load Testing**: Locust distribuido para pruebas de carga
- âœ… **AutomatizaciÃ³n Completa**: Ansible + eksctl
- âœ… **Optimizado para Free Tier**: Minimiza costos en cuentas nuevas

---

## ğŸ—ï¸ Arquitectura

```
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚   AWS Cloud         â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         VPC (10.0.0.0/16)               â”‚
                    â”‚                                          â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚    EKS Cluster                     â”‚ â”‚
                    â”‚  â”‚                                    â”‚ â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
                    â”‚  â”‚  â”‚  Control Plane (Managed)     â”‚ â”‚ â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
                    â”‚  â”‚                                    â”‚ â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
                    â”‚  â”‚  â”‚  Worker Nodes (EC2)          â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”‚ Cluster Autoscaler     â”‚  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”‚ (Escala Nodos)         â”‚  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚                               â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  Min: 2 nodes (t3.medium)    â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  Max: 5 nodes                â”‚ â”‚ â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
                    â”‚  â”‚                                    â”‚ â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
                    â”‚  â”‚  â”‚  Application Pods            â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”‚ HPA                    â”‚  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â”‚ (Escala Pods)          â”‚  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚                               â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  Min: 2 pods                 â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  Max: 10 pods                â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  Triggers: CPU 50%, Mem 70%  â”‚ â”‚ â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
                    â”‚  â”‚                                    â”‚ â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
                    â”‚  â”‚  â”‚  Monitoring Stack            â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â€¢ Prometheus                â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â€¢ Grafana                   â”‚ â”‚ â”‚
                    â”‚  â”‚  â”‚  â€¢ Metrics Server            â”‚ â”‚ â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚                                          â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚    Elastic Load Balancers          â”‚ â”‚
                    â”‚  â”‚  â€¢ Application                     â”‚ â”‚
                    â”‚  â”‚  â€¢ Locust UI                       â”‚ â”‚
                    â”‚  â”‚  â€¢ Grafana                         â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Componentes

### Cluster Autoscaler

**PolÃ­ticas de Scaling de Nodos**:

```yaml
Scale Up:
  - Trigger: Pods en estado Pending (sin recursos)
  - AcciÃ³n: Crear nueva instancia EC2 t3.medium
  - Tiempo: ~3-5 minutos
  - MÃ¡ximo: 5 nodos

Scale Down:
  - Trigger: UtilizaciÃ³n < 50% por 10 minutos
  - Delay: 10 minutos despuÃ©s de scale up
  - AcciÃ³n: Terminar instancia EC2
  - ProtecciÃ³n: No elimina nodos con pods del sistema
```

### HPA (Horizontal Pod Autoscaler)

**PolÃ­ticas de Scaling de Pods**:

```yaml
MÃ©tricas:
  - CPU: 50% utilizaciÃ³n promedio
  - Memory: 70% utilizaciÃ³n promedio

Scale Up:
  - Duplica pods cada 15 segundos
  - MÃ¡ximo 4 pods por ciclo
  - Sin delay (respuesta inmediata)

Scale Down:
  - Reduce 50% cada 15 segundos
  - Stabilization window: 5 minutos
  - Comportamiento conservador
```

---

## ğŸ› ï¸ Prerequisitos

### Software Requerido

```bash
# AWS CLI
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# eksctl
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin

# kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Ansible
pip install ansible
```

### Cuenta AWS

- âœ… Cuenta AWS activa
- âœ… Credenciales configuradas (`aws configure`)
- âœ… Permisos para crear:
  - EKS clusters
  - EC2 instances
  - VPCs, subnets, security groups
  - IAM roles y polÃ­ticas
  - Load Balancers
  - EBS volumes

### Verificar ConfiguraciÃ³n

```bash
# Verificar AWS CLI
aws sts get-caller-identity

# Verificar regiÃ³n
aws configure get region
# Debe retornar: us-east-1
```

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Script Interactivo (Recomendado)

```bash
# Hacer el script ejecutable
chmod +x aws-eks-manager.sh

# Ejecutar el menÃº interactivo
./aws-eks-manager.sh

# Selecciona opciÃ³n 1: Desplegar Cluster EKS Completo
```

**Tiempo estimado**: 20-25 minutos

### OpciÃ³n 2: Comandos Manuales

```bash
# 1. Crear cluster EKS
cd ansible-aws
eksctl create cluster -f cluster-config.yaml

# 2. Configurar kubectl
aws eks update-kubeconfig --name k8s-autoscaling-cluster --region us-east-1

# 3. Agregar repo Helm de Bitnami
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

# 4. Desplegar componentes
ansible-playbook deploy-eks-autoscaling.yml

# 5. Verificar despliegue
kubectl get nodes
kubectl get pods --all-namespaces
kubectl get hpa
```

---

## ğŸ“Š Uso

### Ver Estado del Cluster

```bash
# OpciÃ³n 1: Script
./aws-eks-manager.sh status

# OpciÃ³n 2: Manual
kubectl get nodes
kubectl get hpa
kubectl get pods -l app=do-sample-app
kubectl get deployment cluster-autoscaler -n kube-system
```

### Monitorear en Tiempo Real

```bash
# HPA
./aws-eks-manager.sh monitor-hpa
# O: kubectl get hpa -w

# Pods
./aws-eks-manager.sh monitor-pods
# O: kubectl get pods -l app=do-sample-app -w

# Nodos
./aws-eks-manager.sh monitor-nodes
# O: kubectl get nodes -w

# Logs del Cluster Autoscaler
./aws-eks-manager.sh logs
# O: kubectl logs -f deployment/cluster-autoscaler -n kube-system
```

### Ejecutar Prueba de Carga

```bash
# 1. Obtener URL de Locust
./aws-eks-manager.sh load-test

# 2. Abrir en navegador: http://<LOCUST-URL>:8089

# 3. Configurar prueba:
#    - Usuarios: 100
#    - Spawn rate: 10/s
#    - Host: http://do-sample-app-service:8080

# 4. Click "Start swarming"

# 5. En otra terminal, monitorear:
./aws-eks-manager.sh monitor-hpa
./aws-eks-manager.sh monitor-nodes
```

### Acceder a Grafana

```bash
# Obtener URL y contraseÃ±a
kubectl get svc prometheus-grafana -n monitoring
kubectl get secret prometheus-grafana -n monitoring -o jsonpath="{.data.admin-password}" | base64 -d

# Abrir en navegador: http://<GRAFANA-URL>
# Usuario: admin
# ContraseÃ±a: <output del comando anterior>
```

---

## ğŸ¯ Escenarios de Prueba

### Escenario 1: Scale Up de Pods (Sin Scale Up de Nodos)

**Objetivo**: Ver HPA escalando pods dentro de los nodos existentes.

```bash
# 1. Estado inicial
kubectl get nodes
kubectl get pods -l app=do-sample-app
# DeberÃ­a ver: 2 nodos, 2 pods

# 2. Generar carga moderada en Locust
#    Usuarios: 50, Spawn rate: 5/s

# 3. Observar en 2-3 minutos
kubectl get hpa -w
# DeberÃ­a ver: 2 â†’ 4 â†’ 6 pods
# Nodos se mantienen en 2
```

### Escenario 2: Scale Up de Nodos (Pods Pending)

**Objetivo**: Ver Cluster Autoscaler creando nuevos nodos EC2.

```bash
# 1. Estado inicial
kubectl get nodes
# DeberÃ­a ver: 2 nodos

# 2. Generar carga alta en Locust
#    Usuarios: 200, Spawn rate: 20/s

# 3. Observar HPA escalando pods
kubectl get hpa -w
# 2 â†’ 4 â†’ 6 â†’ 8 â†’ 10 pods

# 4. Algunos pods quedarÃ¡n en Pending
kubectl get pods -l app=do-sample-app
# VerÃ¡s pods en estado: Pending

# 5. Cluster Autoscaler detectarÃ¡ esto
kubectl logs -f deployment/cluster-autoscaler -n kube-system
# VerÃ¡s logs: "Scale-up: creating new node..."

# 6. En 3-5 minutos, nuevo nodo aparece
kubectl get nodes -w
# 2 â†’ 3 nodos (nueva instancia EC2)

# 7. Pods Pending se programan en el nuevo nodo
kubectl get pods -l app=do-sample-app -o wide
```

### Escenario 3: Scale Down Completo

**Objetivo**: Ver scale down de pods y luego de nodos.

```bash
# 1. DespuÃ©s de tener carga alta (3+ nodos, 8+ pods)

# 2. Detener carga en Locust
#    Click "Stop"

# 3. HPA empieza scale down despuÃ©s de 5 minutos
kubectl get hpa -w
# 10 â†’ 8 â†’ 6 â†’ 4 â†’ 3 â†’ 2 pods

# 4. Cluster Autoscaler espera 10 minutos de baja utilizaciÃ³n
kubectl logs -f deployment/cluster-autoscaler -n kube-system
# VerÃ¡s: "node X is underutilized"

# 5. DespuÃ©s de 10 minutos, elimina nodos extra
kubectl get nodes -w
# 3 â†’ 2 nodos

# 6. Pods se re-programan en nodos restantes
kubectl get pods -l app=do-sample-app -o wide
```

---

## ğŸ“ˆ MÃ©tricas y Observabilidad

### Dashboards de Grafana

1. **Kubernetes / Compute Resources / Cluster**
   - CPU y Memory del cluster completo
   - UtilizaciÃ³n por nodo

2. **Kubernetes / Compute Resources / Namespace (Pods)**
   - CPU y Memory por pod
   - Request rate

3. **Cluster Autoscaler**
   - Eventos de scaling
   - Nodos agregados/removidos
   - Pods pending

### Comandos Ãštiles

```bash
# MÃ©tricas en tiempo real
kubectl top nodes
kubectl top pods -l app=do-sample-app

# Eventos del cluster (ver scaling)
kubectl get events --sort-by='.lastTimestamp' | grep -E 'ScalingReplicaSet|TriggeredScaleUp'

# Describir HPA (ver targets y eventos)
kubectl describe hpa do-sample-app-hpa

# Estado del Auto Scaling Group (nodos)
aws autoscaling describe-auto-scaling-groups --region us-east-1 | jq '.AutoScalingGroups[] | select(.AutoScalingGroupName | contains("eks"))'

# Activity history del ASG
aws autoscaling describe-scaling-activities --auto-scaling-group-name <ASG-NAME> --max-records 10
```

---

## ğŸ’° Costos Estimados

### Free Tier (Primeros 12 meses)

| Componente | Cantidad | Costo/mes | Free Tier | Real |
|------------|----------|-----------|-----------|------|
| EKS Control Plane | 1 | $73.00 | $73.00 | $0.00* |
| EC2 t3.medium | 2-5 | $30.37 c/u | 750h gratis | ~$15-30 |
| EBS gp3 | ~60GB | $0.08/GB | - | ~$5 |
| Load Balancers | 3 | $16.20 c/u | - | ~$49 |
| **Total estimado** | | | | **$70-85/mes** |

\* *EKS Free Tier vÃ¡lido 12 meses desde creaciÃ³n de cuenta*

### Sin Free Tier

- **Costo mensual**: ~$150-200
- **Costo por hora**: ~$0.20-0.27

### Recomendaciones para Minimizar Costos

```bash
# 1. Destruir cluster cuando no lo uses
./aws-eks-manager.sh destroy

# 2. Usar instancias Spot (70% descuento)
# Editar ansible-aws/cluster-config.yaml:
# managedNodeGroups[0].spot: true

# 3. Reducir LoadBalancers
# Cambiar servicios a NodePort en manifests-aws/*.yaml

# 4. Usar t3.small en lugar de t3.medium
# Editar ansible-aws/cluster-config.yaml:
# managedNodeGroups[0].instanceType: t3.small
```

---

## ğŸ§¹ Limpieza

### Limpiar Componentes (Mantener Cluster)

```bash
# OpciÃ³n 1: Script
./aws-eks-manager.sh cleanup

# OpciÃ³n 2: Ansible
cd ansible-aws
ansible-playbook cleanup-eks.yml
```

Esto elimina:
- âœ… AplicaciÃ³n y HPA
- âœ… Locust
- âœ… Cluster Autoscaler
- âœ… Prometheus y Grafana
- âœ… Metrics Server

Mantiene:
- âŒ Cluster EKS
- âŒ Nodos EC2
- âŒ VPC y networking

### Destruir Cluster Completo

```bash
# OpciÃ³n 1: Script (solicita confirmaciÃ³n)
./aws-eks-manager.sh destroy

# OpciÃ³n 2: Manual
eksctl delete cluster --name k8s-autoscaling-cluster --region us-east-1
```

**âš ï¸ ADVERTENCIA**: Esto elimina TODO de forma permanente.

**Tiempo estimado**: 10-15 minutos

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Modificar PolÃ­ticas del Cluster Autoscaler

Editar `manifests-aws/cluster-autoscaler.yaml`:

```yaml
# LÃ­neas 70-80 del deployment
- --scale-down-delay-after-add=10m      # Espera despuÃ©s de agregar nodo
- --scale-down-unneeded-time=10m        # Tiempo de baja utilizaciÃ³n
- --scale-down-utilization-threshold=0.5 # 50% de utilizaciÃ³n
- --max-node-provision-time=15m         # Timeout para crear nodo
```

### Modificar LÃ­mites del Node Group

Editar `ansible-aws/cluster-config.yaml`:

```yaml
managedNodeGroups:
  - name: worker-nodes
    desiredCapacity: 2
    minSize: 1          # Cambiar mÃ­nimo
    maxSize: 10         # Cambiar mÃ¡ximo
    instanceType: t3.large  # Cambiar tipo
```

Aplicar cambios:

```bash
eksctl scale nodegroup --cluster=k8s-autoscaling-cluster --name=worker-nodes --nodes-min=1 --nodes-max=10
```

### Usar Instancias Spot

Editar `ansible-aws/cluster-config.yaml`:

```yaml
managedNodeGroups:
  - name: worker-nodes
    # ... configuraciÃ³n existente ...
    spot: true
    instancesDistribution:
      maxPrice: 0.05  # Precio mÃ¡ximo por hora
      instanceTypes:
        - t3.medium
        - t3a.medium
        - t2.medium
      onDemandBaseCapacity: 0
      onDemandPercentageAboveBaseCapacity: 0
      spotInstancePools: 3
```

---

## ğŸ› Troubleshooting

### Pods en Pending despuÃ©s de mucho tiempo

```bash
# Ver eventos del pod
kubectl describe pod <pod-name>

# Posibles causas:
# 1. LÃ­mite de nodos alcanzado (maxSize en cluster-config.yaml)
# 2. Cuota de EC2 excedida
# 3. Problemas con IAM roles del Cluster Autoscaler

# Verificar logs del Cluster Autoscaler
kubectl logs -f deployment/cluster-autoscaler -n kube-system | grep -i error
```

### Cluster Autoscaler no crea nodos

```bash
# 1. Verificar que el deployment estÃ© corriendo
kubectl get deployment cluster-autoscaler -n kube-system

# 2. Ver logs detallados
kubectl logs -f deployment/cluster-autoscaler -n kube-system

# 3. Verificar IAM role
kubectl describe sa cluster-autoscaler -n kube-system
# Debe tener annotation: eks.amazonaws.com/role-arn

# 4. Verificar tags del ASG
aws autoscaling describe-auto-scaling-groups --region us-east-1 | \
  jq '.AutoScalingGroups[] | select(.AutoScalingGroupName | contains("eks")) | .Tags'
# Debe tener: k8s.io/cluster-autoscaler/enabled: true
```

### HPA muestra `<unknown>` en targets

```bash
# Verificar Metrics Server
kubectl get deployment metrics-server -n kube-system
kubectl logs -n kube-system deployment/metrics-server

# Esperar 1-2 minutos despuÃ©s del despliegue
kubectl top nodes
kubectl top pods

# Si aÃºn falla, reinstalar
kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### LoadBalancers en estado Pending

```bash
# Ver eventos del servicio
kubectl describe svc <service-name>

# Verificar AWS Load Balancer Controller
kubectl get deployment -n kube-system

# Si falta el controller, instalarlo:
curl -o iam-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
aws iam create-policy --policy-name AWSLoadBalancerControllerIAMPolicy --policy-document file://iam-policy.json
```

---

## ğŸ“š Referencias

### DocumentaciÃ³n Oficial

- [AWS EKS Documentation](https://docs.aws.amazon.com/eks/)
- [Cluster Autoscaler on AWS](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md)
- [HPA Documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [eksctl Documentation](https://eksctl.io/)

### Arquitectura del Proyecto

```
k8s-on-digital-ocean-main/
â”œâ”€â”€ ansible-aws/                    # ConfiguraciÃ³n Ansible para AWS
â”‚   â”œâ”€â”€ ansible.cfg
â”‚   â”œâ”€â”€ inventory.ini
â”‚   â”œâ”€â”€ cluster-config.yaml         # ConfiguraciÃ³n del cluster EKS
â”‚   â”œâ”€â”€ deploy-eks-autoscaling.yml  # Playbook de despliegue
â”‚   â””â”€â”€ cleanup-eks.yml             # Playbook de limpieza
â”‚
â”œâ”€â”€ manifests-aws/                  # Manifests de Kubernetes para AWS
â”‚   â”œâ”€â”€ application.yaml            # Deployment + LoadBalancer
â”‚   â”œâ”€â”€ hpa.yaml                    # HPA configuration
â”‚   â”œâ”€â”€ locust.yaml                 # Load testing
â”‚   â”œâ”€â”€ cluster-autoscaler.yaml     # Cluster Autoscaler
â”‚   â”œâ”€â”€ storage-class.yaml          # EBS GP3 storage
â”‚   â”œâ”€â”€ postgres-pv.yaml            # PostgreSQL volume
â”‚   â””â”€â”€ postgres-connection.yaml    # Database secret
â”‚
â”œâ”€â”€ aws-eks-manager.sh              # Script de gestiÃ³n interactivo
â””â”€â”€ README-AWS.md                   # Este archivo
```

---

## ğŸ“ Aprendizajes Clave

### Diferencias vs DigitalOcean

| Aspecto | AWS EKS | DigitalOcean K8s |
|---------|---------|------------------|
| **Cluster Autoscaler** | âœ… Completo | âŒ BÃ¡sico |
| **PolÃ­ticas de Scaling** | âœ… Avanzadas | âŒ Min/Max simple |
| **Tipos de Instancia** | âœ… 400+ opciones | âŒ Limitado |
| **Spot Instances** | âœ… SÃ­ (70% descuento) | âŒ No |
| **Complejidad** | ğŸ”´ Alta | ğŸŸ¢ Baja |
| **Costo** | ğŸ”´ Mayor | ğŸŸ¢ Menor |
| **Free Tier** | âœ… 12 meses | âŒ No |

### Conceptos Demostrados

1. **Autoscaling de Dos Niveles**:
   - HPA escala pods horizontalmente
   - Cluster Autoscaler escala nodos (infraestructura)

2. **PolÃ­ticas Avanzadas**:
   - Delays configurables
   - Thresholds personalizados
   - Comportamiento de scale up/down diferenciado

3. **IAM Roles for Service Accounts (IRSA)**:
   - AutenticaciÃ³n segura entre K8s y AWS
   - No credentials hardcodeadas

4. **Infrastructure as Code**:
   - Cluster definido en YAML (eksctl)
   - Despliegue automatizado (Ansible)
   - Reproducible y versionable

---

## ğŸ¤ Contribuciones

Este proyecto es parte de una demostraciÃ³n de autoscaling en Kubernetes. Originalmente configurado para DigitalOcean, ahora adaptado para AWS EKS con capacidades avanzadas de autoscaling.

### PrÃ³ximas Mejoras

- [ ] IntegraciÃ³n con AWS CloudWatch Alarms
- [ ] Autoscaling basado en mÃ©tricas custom (RPS, latencia)
- [ ] Multi-region deployment
- [ ] GitOps con ArgoCD
- [ ] Service Mesh con Istio
- [ ] Karpenter como alternativa al Cluster Autoscaler

---

## ğŸ“ Soporte

### Comandos de DiagnÃ³stico

```bash
# InformaciÃ³n completa del cluster
./aws-eks-manager.sh status

# Logs de todos los componentes
kubectl logs -n kube-system deployment/cluster-autoscaler
kubectl logs deployment/do-sample-app
kubectl logs -n monitoring deployment/prometheus-operator

# Exportar configuraciÃ³n para anÃ¡lisis
kubectl get all --all-namespaces -o yaml > cluster-state.yaml
kubectl describe nodes > nodes-info.txt
kubectl get events --sort-by='.lastTimestamp' > events.txt
```

### Recursos de Ayuda

- ğŸ“– [EKS Workshop](https://www.eksworkshop.com/)
- ğŸ’¬ [AWS EKS Forum](https://repost.aws/tags/TABhLMKzZLSZyb8w2S_wFsLQ/amazon-elastic-kubernetes-service)
- ğŸ› [Cluster Autoscaler FAQ](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md)

---

**Creado con â¤ï¸ para demostrar Kubernetes Autoscaling en AWS EKS**
